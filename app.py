#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Instagram Automation avec Ollama
Application Flask pour automatiser les publications Instagram avec IA locale
"""

import os
import sys
import logging
import atexit
import argparse
import subprocess
import platform
from flask import Flask, jsonify
import json
from datetime import datetime
from config import Config

# Ajouter le r√©pertoire courant au path Python
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

print("üöÄ D√©marrage Instagram Automation avec Ollama...")

# Imports de base
try:
    from config import Config, config
    from database import DatabaseManager
    from models import Post, PostStatus, ContentTone
    print("‚úÖ Imports de base r√©ussis")
except ImportError as e:
    print(f"‚ùå Erreur imports de base: {e}")
    sys.exit(1)


def import_services():
    """Importe tous les services disponibles (VERSION COMPL√àTE)"""
    services = {}
    
    # Service de base de donn√©es
    try:
        from database import DatabaseManager
        services['db_manager'] = DatabaseManager
        print("‚úÖ Service base de donn√©es disponible")
    except ImportError as e:
        print(f"‚ùå Erreur service base de donn√©es: {e}")
        services['db_manager'] = None
    
    # Services de contenu IA (Ollama en priorit√©)
    try:
        if Config.USE_OLLAMA:
            from services.ollama_generator import OllamaContentGenerator
            services['ollama_content'] = OllamaContentGenerator
            print("‚úÖ Service Ollama disponible")
        else:
            print("‚ö†Ô∏è  Ollama d√©sactiv√© dans la configuration")
            services['ollama_content'] = None
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Ollama non disponible: {e}")
        services['ollama_content'] = None
    
    # Services OpenAI (fallback)
    try:
        from services.ai_generator import AIImageGenerator
        from services.content_generator import ContentGenerator
        services['openai_image'] = AIImageGenerator
        services['openai_content'] = ContentGenerator
        print("‚úÖ Services OpenAI disponibles")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Services OpenAI non disponibles: {e}")
        services['openai_image'] = None
        services['openai_content'] = None
    
    # Service Stable Diffusion (images)
    try:
        from services.stable_diffusion_generator import StableDiffusionGenerator
        services['stable_diffusion'] = StableDiffusionGenerator
        print("‚úÖ Service Stable Diffusion disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Stable Diffusion non disponible: {e}")
        services['stable_diffusion'] = None
    
    # Service Hugging Face (images alternative)
    try:
        from services.stable_diffusion_generator import HuggingFaceGenerator
        services['huggingface'] = HuggingFaceGenerator
        print("‚úÖ Service Hugging Face disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Hugging Face non disponible: {e}")
        services['huggingface'] = None
    
    # Service Stable Video Diffusion (NOUVEAU)
    try:
        from services.stable_video_diffusion_generator import StableVideoDiffusionGenerator
        services['svd_generator'] = StableVideoDiffusionGenerator
        print("‚úÖ Service Stable Video Diffusion disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service SVD non disponible: {e}")
        services['svd_generator'] = None
    
    # Service Instagram
    try:
        from services.instagram_api import InstagramPublisher
        services['instagram'] = InstagramPublisher
        print("‚úÖ Service Instagram disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Instagram non disponible: {e}")
        services['instagram'] = None
    
    # Scheduler
    try:
        from utils.scheduler import PostScheduler
        services['scheduler'] = PostScheduler
        print("‚úÖ Scheduler disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Scheduler non disponible: {e}")
        services['scheduler'] = None
    
    return services


def import_routes():
    """Importe les routes disponibles"""
    try:
        from routes.main import main_bp
        from routes.api import api_bp
        print("‚úÖ Routes import√©es")
        return main_bp, api_bp, True
    except ImportError as e:
        print(f"‚ö†Ô∏è  Erreur import routes: {e}")
        return create_fallback_routes()


def create_fallback_routes():
    """Cr√©e des routes de secours"""
    from flask import Blueprint, render_template_string
    
    main_bp = Blueprint('main', __name__)
    api_bp = Blueprint('api', __name__)
    
    @main_bp.route('/')
    def index():
        return render_template_string(get_fallback_template())
    
    @api_bp.route('/status')
    def api_status():
        return jsonify({
            'status': 'running',
            'mode': 'fallback',
            'message': 'Application en mode d√©grad√©'
        })
    
    return main_bp, api_bp, False


def get_fallback_template():
    """Template de secours"""
    return '''
<!DOCTYPE html>
<html>
<head>
    <title>Instagram Automation - Configuration</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <style>
        body { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }
        .card { box-shadow: 0 10px 30px rgba(0,0,0,0.3); border: none; }
        .gradient-text { background: linear-gradient(45deg, #667eea, #764ba2); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    </style>
</head>
<body>
    <div class="container mt-5">
        <div class="row justify-content-center">
            <div class="col-lg-8">
                <div class="card">
                    <div class="card-body p-5 text-center">
                        <h1 class="display-4 gradient-text mb-4">
                            <i class="fab fa-instagram me-3"></i>Instagram Automation
                        </h1>
                        <p class="lead text-muted mb-4">Application en cours de configuration avec Ollama</p>
                        
                        <div class="row mb-4">
                            <div class="col-md-4">
                                <div class="p-3 bg-light rounded">
                                    <i class="fas fa-robot fa-2x text-primary mb-2"></i>
                                    <h6>IA Locale</h6>
                                    <small class="text-muted">Ollama + Mistral</small>
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="p-3 bg-light rounded">
                                    <i class="fab fa-instagram fa-2x text-danger mb-2"></i>
                                    <h6>Publication</h6>
                                    <small class="text-muted">Instagram API</small>
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="p-3 bg-light rounded">
                                    <i class="fas fa-clock fa-2x text-warning mb-2"></i>
                                    <h6>Automatisation</h6>
                                    <small class="text-muted">Scheduler</small>
                                </div>
                            </div>
                        </div>
                        
                        <div class="alert alert-info">
                            <h6><i class="fas fa-info-circle me-2"></i>Configuration Ollama</h6>
                            <ol class="text-start">
                                <li>Installer Ollama: <code>curl -fsSL https://ollama.ai/install.sh | sh</code></li>
                                <li>D√©marrer Ollama: <code>ollama serve</code></li>
                                <li>T√©l√©charger Mistral: <code>ollama pull mistral:latest</code></li>
                                <li>Red√©marrer l'application</li>
                            </ol>
                        </div>
                        
                        <div class="d-flex gap-3 justify-content-center">
                            <a href="/health" class="btn btn-success">
                                <i class="fas fa-heartbeat me-2"></i>V√©rifier l'√©tat
                            </a>
                            <a href="/debug" class="btn btn-outline-primary">
                                <i class="fas fa-bug me-2"></i>Informations debug
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
    '''


def create_app(config_name='default'):
    """Factory pour cr√©er l'application Flask"""
    
    # Cr√©er l'application Flask
    app = Flask(__name__)
    
    # Configuration
    config_class = config.get(config_name, config['default'])
    app.config.from_object(config_class)
    config_class.init_app(app)
    
    # Configuration des logs
    setup_logging(app)
    
    # Import des services et routes
    services = import_services()
    main_bp, api_bp, routes_ok = import_routes()
    
    # Initialisation des services
    init_services(app, services)
    
    # Enregistrement des blueprints
    app.register_blueprint(main_bp)
    app.register_blueprint(api_bp, url_prefix='/api')
    
    # Routes syst√®me
    setup_system_routes(app, services, routes_ok)
    
    # Gestionnaires d'erreurs
    setup_error_handlers(app)
    
    print("‚úÖ Application Flask cr√©√©e avec succ√®s")
    return app


def setup_logging(app):
    """Configure le syst√®me de logs"""
    if not app.debug:
        if not os.path.exists('logs'):
            os.makedirs('logs')
        
        file_handler = logging.FileHandler('logs/instagram_automation.log')
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
        ))
        file_handler.setLevel(logging.INFO)
        app.logger.addHandler(file_handler)
        app.logger.setLevel(logging.INFO)
        app.logger.info('Instagram Automation startup with Ollama')

def get_active_image_service_name(app) -> str:
    """Retourne le nom du service d'images actif"""
    if hasattr(app, 'sd_generator') and app.sd_generator and getattr(app.sd_generator, 'is_available', False):
        return "Stable Diffusion"
    elif hasattr(app, 'hf_generator') and app.hf_generator:
        return "Hugging Face"
    elif hasattr(app, 'image_generator') and app.image_generator and not hasattr(app.image_generator, 'is_available'):
        return "OpenAI DALL-E"
    else:
        return "Non disponible"


def init_services(app, services):
    """Initialise tous les services de l'application (VERSION CORRIG√âE)"""
    
    # Base de donn√©es - CORRECTION
    if services.get('db_manager'):
        try:
            app.db_manager = services['db_manager'](Config.DATABASE_PATH)
            print("‚úÖ Base de donn√©es initialis√©e")
        except Exception as e:
            print(f"‚ùå Erreur base de donn√©es: {e}")
            print("üí° Lancez: python database_fix.py pour corriger")
            app.db_manager = None
    else:
        app.db_manager = None
    
    # Services IA - CORRECTION POUR LES IMAGES
    app.content_generator = None
    app.image_generator = None
    app.sd_generator = None
    app.hf_generator = None
    
    print("\nüìù Configuration g√©n√©ration de contenu...")
    
    # 1. G√âN√âRATEUR DE CONTENU (Ollama en priorit√©)
    if Config.USE_OLLAMA and services.get('ollama_content'):
        try:
            app.content_generator = services['ollama_content'](
                base_url=Config.OLLAMA_BASE_URL,
                model=Config.OLLAMA_MODEL
            )
            print(f"‚úÖ G√©n√©rateur de contenu Ollama - Mod√®le: {Config.OLLAMA_MODEL}")
        except Exception as e:
            print(f"‚ùå Erreur services Ollama: {e}")
            # Fallback vers OpenAI si disponible
            if services.get('openai_content') and Config.OPENAI_API_KEY:
                try:
                    app.content_generator = services['openai_content'](Config.OPENAI_API_KEY)
                    print("üîÑ Fallback vers OpenAI pour le contenu")
                except Exception as e2:
                    print(f"‚ùå Erreur fallback OpenAI: {e2}")
    elif services.get('openai_content') and Config.OPENAI_API_KEY:
        try:
            app.content_generator = services['openai_content'](Config.OPENAI_API_KEY)
            print("‚úÖ G√©n√©rateur de contenu OpenAI initialis√©")
        except Exception as e:
            print(f"‚ùå Erreur service OpenAI: {e}")
    
    print("\nüé® Configuration g√©n√©ration d'images...")
    
    # 2. G√âN√âRATEUR D'IMAGES - CORRECTION MAJEURE
    
    # A. Stable Diffusion (priorit√© 1 - gratuit et local)
    if Config.USE_STABLE_DIFFUSION:
        try:
            from services.stable_diffusion_generator import StableDiffusionGenerator
            app.sd_generator = StableDiffusionGenerator(Config.STABLE_DIFFUSION_URL)
            if app.sd_generator.is_available:
                app.image_generator = app.sd_generator  # Utiliser SD comme g√©n√©rateur principal
                print("‚úÖ Stable Diffusion configur√© comme g√©n√©rateur d'images principal")
            else:
                print(f"‚ö†Ô∏è  Stable Diffusion configur√© mais non disponible sur {Config.STABLE_DIFFUSION_URL}")
                print("üí° D√©marrez l'interface web avec: python launch.py --api")
        except ImportError as e:
            print(f"‚ùå Module Stable Diffusion manquant: {e}")
            print("üí° Le fichier services/stable_diffusion_generator.py est requis")
        except Exception as e:
            print(f"‚ùå Erreur Stable Diffusion: {e}")
    
    # B. Hugging Face (priorit√© 2 - gratuit en ligne)
    if Config.USE_HUGGINGFACE and not app.image_generator:
        try:
            from services.stable_diffusion_generator import HuggingFaceGenerator
            app.hf_generator = HuggingFaceGenerator(Config.HUGGINGFACE_API_TOKEN)
            app.image_generator = app.hf_generator
            print("‚úÖ Hugging Face configur√© comme g√©n√©rateur d'images")
        except ImportError as e:
            print(f"‚ùå Module Hugging Face manquant: {e}")
        except Exception as e:
            print(f"‚ùå Erreur Hugging Face: {e}")
    
    # C. OpenAI DALL-E (priorit√© 3 - payant mais fiable)
    if Config.OPENAI_API_KEY and not app.image_generator:
        try:
            # V√©rifier si le module OpenAI est disponible
            import openai
            from services.ai_generator import AIImageGenerator
            openai_generator = AIImageGenerator(Config.OPENAI_API_KEY)
            app.image_generator = openai_generator
            print("‚úÖ OpenAI DALL-E configur√© comme g√©n√©rateur d'images")
        except ImportError as e:
            print(f"‚ùå Module OpenAI manquant: {e}")
            print("üí° Installez avec: pip install openai")
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©rateur d'images OpenAI: {e}")
    
    # D. G√âN√âRATEUR PLACEHOLDER si aucun service disponible
    if not app.image_generator:
        print("‚ö†Ô∏è  Aucun service de g√©n√©ration d'images disponible")
        print("üí° Pour activer la g√©n√©ration d'images:")
        print("   1. Stable Diffusion: D√©marrez l'interface web avec --api")
        print("   2. Hugging Face: Ajoutez HUGGINGFACE_API_TOKEN=your_token dans .env")
        print("   3. OpenAI: Installez openai et ajoutez OPENAI_API_KEY dans .env")
        
        # Cr√©er un g√©n√©rateur factice pour √©viter les erreurs
        class PlaceholderImageGenerator:
            def generate_image(self, prompt, **kwargs):
                from models import ImageGenerationResult
                return ImageGenerationResult.error_result(
                    "Aucun service de g√©n√©ration d'images configur√©", prompt
                )
            
            def validate_prompt(self, prompt):
                return True, "OK"
        
        app.image_generator = PlaceholderImageGenerator()
        print("üîß G√©n√©rateur placeholder cr√©√© (pas de g√©n√©ration r√©elle)")
    
    # R√©sum√© des services d'images
    if hasattr(app.image_generator, 'is_available'):
        if app.sd_generator and app.sd_generator.is_available:
            service_name = "Stable Diffusion"
        elif app.hf_generator:
            service_name = "Hugging Face"
        else:
            service_name = "Inconnu"
    elif hasattr(app.image_generator, 'api_key'):
        service_name = "OpenAI DALL-E"
    else:
        service_name = "Placeholder (aucun service actif)"
    
    print(f"üé® Service d'images actif: {service_name}")
    
    print("\nüì∏ Configuration Instagram...")
    
    # Service Instagram
    if services.get('instagram') and Config.INSTAGRAM_ACCESS_TOKEN and Config.INSTAGRAM_ACCOUNT_ID:
        try:
            app.instagram_publisher = services['instagram'](
                Config.INSTAGRAM_ACCESS_TOKEN,
                Config.INSTAGRAM_ACCOUNT_ID
            )
            print("‚úÖ Service Instagram initialis√©")
        except Exception as e:
            print(f"‚ùå Erreur service Instagram: {e}")
            app.instagram_publisher = None
    else:
        app.instagram_publisher = None
        missing_config = []
        if not Config.INSTAGRAM_ACCESS_TOKEN:
            missing_config.append("INSTAGRAM_ACCESS_TOKEN")
        if not Config.INSTAGRAM_ACCOUNT_ID:
            missing_config.append("INSTAGRAM_ACCOUNT_ID")
        if missing_config:
            print(f"‚ö†Ô∏è  Configuration Instagram manquante: {', '.join(missing_config)}")
    
    print("\n‚è∞ Configuration Scheduler...")
    
    # Scheduler
    if services.get('scheduler') and app.db_manager:
        try:
            app.scheduler = services['scheduler'](app.db_manager, app.instagram_publisher)
            
            # Callbacks du scheduler
            def on_post_published(post, result):
                app.logger.info(f"üì∏ Post publi√© automatiquement: {post.title}")
            
            def on_post_failed(post, error):
                app.logger.error(f"‚ùå √âchec publication automatique: {post.title} - {error}")
            
            def on_scheduler_error(error):
                app.logger.error(f"üö® Erreur scheduler: {error}")
            
            app.scheduler.set_callbacks(on_post_published, on_post_failed, on_scheduler_error)
            app.scheduler.start()
            print("‚úÖ Scheduler d√©marr√©")
        except Exception as e:
            print(f"‚ùå Erreur scheduler: {e}")
            app.scheduler = None
    else:
        app.scheduler = None
        if not app.db_manager:
            print("‚ö†Ô∏è  Scheduler n√©cessite la base de donn√©es")
    
    # R√âSUM√â FINAL
    print("\n" + "=" * 50)
    print("üìä R√âSUM√â DES SERVICES")
    print("=" * 50)
    
    services_status = {
        'Base de donn√©es': '‚úÖ' if app.db_manager else '‚ùå',
        'Contenu (IA)': '‚úÖ' if app.content_generator else '‚ùå',
        'Images (IA)': '‚úÖ' if app.image_generator and not isinstance(app.image_generator, type(app.image_generator)) or hasattr(app.image_generator, 'api_key') or (hasattr(app.image_generator, 'is_available') and app.image_generator.is_available) else '‚ùå',
        'Instagram': '‚úÖ' if app.instagram_publisher else '‚ö†Ô∏è',
        'Scheduler': '‚úÖ' if app.scheduler else '‚ö†Ô∏è'
    }
    
    for service, status in services_status.items():
        print(f"{status} {service}")
    
    # Service IA actif
    ai_services = []
    if app.content_generator:
        if hasattr(app.content_generator, 'model'):
            ai_services.append(f"Contenu: Ollama ({app.content_generator.model})")
        else:
            ai_services.append("Contenu: OpenAI")
    
    if app.image_generator:
        if hasattr(app.image_generator, 'is_available'):
            if app.sd_generator and app.sd_generator.is_available:
                ai_services.append("Images: Stable Diffusion")
            elif app.hf_generator:
                ai_services.append("Images: Hugging Face")
        elif hasattr(app.image_generator, 'api_key'):
            ai_services.append("Images: OpenAI DALL-E")
        else:
            ai_services.append("Images: Non disponible")
    
    if ai_services:
        print(f"\nüéØ Services IA actifs: {', '.join(ai_services)}")
    else:
        print(f"\n‚ö†Ô∏è  Aucun service IA actif")
    
    # Score
    active_count = sum(1 for status in services_status.values() if status == '‚úÖ')
    total_count = len(services_status)
    print(f"\nüìà Score: {active_count}/{total_count} services actifs")
    
    if active_count >= 4:
        print("‚úÖ Configuration compl√®te")
    elif active_count >= 2:
        print("‚ö†Ô∏è  Configuration minimale - Certaines fonctionnalit√©s limit√©es")
    else:
        print("‚ùå Configuration insuffisante")

    # 3. G√âN√âRATEUR DE VID√âOS - STABLE VIDEO DIFFUSION
    app.svd_generator = None
    
    if Config.USE_STABLE_VIDEO_DIFFUSION:
        try:
            from services.stable_video_diffusion_generator import StableVideoDiffusionGenerator
            app.svd_generator = StableVideoDiffusionGenerator(Config.SVD_API_URL)
            
            if app.svd_generator.is_available:
                print("‚úÖ Stable Video Diffusion configur√© et accessible")
                
                # Test rapide de la queue
                try:
                    queue_status = app.svd_generator.get_queue_status()
                    running_jobs = len(queue_status.get('queue_running', []))
                    pending_jobs = len(queue_status.get('queue_pending', []))
                    print(f"   üìä Queue: {running_jobs} en cours, {pending_jobs} en attente")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Impossible de v√©rifier la queue: {e}")
            else:
                print(f"‚ö†Ô∏è  Stable Video Diffusion configur√© mais non accessible sur {Config.SVD_API_URL}")
                print("üí° V√©rifiez que ComfyUI est d√©marr√© avec: python main.py --port 7862")
                
        except ImportError as e:
            print(f"‚ùå Module Stable Video Diffusion manquant: {e}")
            print("üí° Le fichier services/stable_video_diffusion_generator.py est requis")
        except Exception as e:
            print(f"‚ùå Erreur Stable Video Diffusion: {e}")
    else:
        print("‚ö†Ô∏è  Stable Video Diffusion d√©sactiv√© dans la configuration")
        print("üí° Pour activer : SET USE_STABLE_VIDEO_DIFFUSION=True dans .env")
    
    # Si aucun g√©n√©rateur de vid√©os n'est disponible
    if not app.svd_generator or not getattr(app.svd_generator, 'is_available', False):
        print("‚ö†Ô∏è  Aucun service de g√©n√©ration de vid√©os disponible")
        print("üí° Pour activer la g√©n√©ration de vid√©os:")
        print("   1. Installez ComfyUI: git clone https://github.com/comfyanonymous/ComfyUI")
        print("   2. T√©l√©chargez SVD: huggingface-cli download stabilityai/stable-video-diffusion-img2vid")
        print("   3. D√©marrez: cd ComfyUI && python main.py --port 7862")
        print("   4. Activez dans .env: USE_STABLE_VIDEO_DIFFUSION=True")
        
        # Cr√©er un g√©n√©rateur factice pour √©viter les erreurs
        class PlaceholderVideoGenerator:
            def __init__(self):
                self.is_available = False
            
            def generate_video_from_image(self, *args, **kwargs):
                from models import VideoGenerationResult
                return VideoGenerationResult.error_result(
                    "Aucun service de g√©n√©ration de vid√©os configur√©"
                )
            
            def generate_video_from_text(self, *args, **kwargs):
                from models import VideoGenerationResult
                return VideoGenerationResult.error_result(
                    "Aucun service de g√©n√©ration de vid√©os configur√©"
                )
            
            def get_status(self):
                return {
                    'available': False,
                    'service': 'Non configur√©'
                }
            
            def get_queue_status(self):
                return {'queue_running': [], 'queue_pending': []}
        
        app.svd_generator = PlaceholderVideoGenerator()
        print("üîß G√©n√©rateur vid√©o placeholder cr√©√©")
    
    # ... (reste du code existant) ...
    
    # R√âSUM√â FINAL (mise √† jour)
    print("\n" + "=" * 50)
    print("üìä R√âSUM√â DES SERVICES")
    print("=" * 50)
    
    services_status = {
        'Base de donn√©es': '‚úÖ' if app.db_manager else '‚ùå',
        'Contenu (IA)': '‚úÖ' if app.content_generator else '‚ùå',
        'Images (IA)': '‚úÖ' if app.image_generator and (not hasattr(app.image_generator, 'is_available') or app.image_generator.is_available) else '‚ùå',
        'Vid√©os (IA)': '‚úÖ' if app.svd_generator and getattr(app.svd_generator, 'is_available', False) else '‚ö†Ô∏è',
        'Instagram': '‚úÖ' if app.instagram_publisher else '‚ö†Ô∏è',
        'Scheduler': '‚úÖ' if app.scheduler else '‚ö†Ô∏è'
    }
    
    for service, status in services_status.items():
        print(f"{status} {service}")
    
    # Services IA actifs (mise √† jour)
    ai_services = []
    if app.content_generator:
        if hasattr(app.content_generator, 'model'):
            ai_services.append(f"Contenu: Ollama ({app.content_generator.model})")
        else:
            ai_services.append("Contenu: OpenAI")
    
    if app.image_generator:
        if hasattr(app.image_generator, 'is_available'):
            if hasattr(app, 'sd_generator') and app.sd_generator and app.sd_generator.is_available:
                ai_services.append("Images: Stable Diffusion")
            elif hasattr(app, 'hf_generator') and app.hf_generator:
                ai_services.append("Images: Hugging Face")
        elif hasattr(app.image_generator, 'api_key'):
            ai_services.append("Images: OpenAI DALL-E")
        else:
            ai_services.append("Images: Non disponible")
    
    if app.svd_generator and getattr(app.svd_generator, 'is_available', False):
        ai_services.append("Vid√©os: Stable Video Diffusion")
    else:
        ai_services.append("Vid√©os: Non disponible")
    
    if ai_services:
        print(f"\nüéØ Services IA actifs: {', '.join(ai_services)}")
    else:
        print(f"\n‚ö†Ô∏è  Aucun service IA actif")
    
    # Score (mise √† jour)
    active_count = sum(1 for status in services_status.values() if status == '‚úÖ')
    total_count = len(services_status)
    print(f"\nüìà Score: {active_count}/{total_count} services actifs")
    
    if active_count >= 5:
        print("‚úÖ Configuration compl√®te")
    elif active_count >= 3:
        print("‚ö†Ô∏è  Configuration fonctionnelle - Certaines fonctionnalit√©s limit√©es")
    else:
        print("‚ùå Configuration insuffisante")


def import_services():
    """Importe les services disponibles (VERSION MISE √Ä JOUR)"""
    services = {}
    
    # Service de base de donn√©es
    try:
        services['db_manager'] = DatabaseManager
        print("‚úÖ Service base de donn√©es disponible")
    except Exception as e:
        print(f"‚ùå Erreur service base de donn√©es: {e}")
        services['db_manager'] = None
    
    # Services IA
    try:
        if Config.USE_OLLAMA:
            from services.ollama_generator import OllamaContentGenerator
            services['ollama_content'] = OllamaContentGenerator
            print("‚úÖ Service Ollama disponible")
        else:
            print("‚ö†Ô∏è  Ollama d√©sactiv√© dans la configuration")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Ollama non disponible: {e}")
        services['ollama_content'] = None
    
    # Services OpenAI (fallback)
    try:
        from services.ai_generator import AIImageGenerator
        from services.content_generator import ContentGenerator
        services['openai_image'] = AIImageGenerator
        services['openai_content'] = ContentGenerator
        print("‚úÖ Services OpenAI disponibles")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Services OpenAI non disponibles: {e}")
        services['openai_image'] = None
        services['openai_content'] = None
    
    # Service Instagram
    try:
        from services.instagram_api import InstagramPublisher
        services['instagram'] = InstagramPublisher
        print("‚úÖ Service Instagram disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Service Instagram non disponible: {e}")
        services['instagram'] = None
    
    # Scheduler
    try:
        from utils.scheduler import PostScheduler
        services['scheduler'] = PostScheduler
        print("‚úÖ Scheduler disponible")
    except ImportError as e:
        print(f"‚ö†Ô∏è  Scheduler non disponible: {e}")
        services['scheduler'] = None
    
    return services

def generate_debug_template(debug_data):
    """G√©n√®re le template HTML de debug"""
    return f'''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Debug - Instagram Automation 2.0</title>
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
        <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
        <style>
            pre {{ background: #f8f9fa; padding: 15px; border-radius: 5px; font-size: 12px; }}
            .status-ok {{ color: #28a745; }}
            .status-error {{ color: #dc3545; }}
            .status-warning {{ color: #ffc107; }}
            .service-card {{ transition: transform 0.2s; }}
            .service-card:hover {{ transform: translateY(-2px); }}
        </style>
    </head>
    <body>
        <div class="container mt-4">
            <div class="row mb-4">
                <div class="col-12">
                    <h1><i class="fas fa-bug me-3"></i>Debug - Instagram Automation 2.0</h1>
                    <p class="text-muted">Informations compl√®tes du syst√®me avec support vid√©o</p>
                </div>
            </div>
            
            <!-- Services Grid -->
            <div class="row mb-4">
                <div class="col-md-4">
                    <div class="card service-card h-100">
                        <div class="card-header bg-primary text-white">
                            <h6><i class="fas fa-brain me-2"></i>G√©n√©ration de Contenu</h6>
                        </div>
                        <div class="card-body">
                            <ul class="list-unstyled">
                                <li>Ollama: <span class="{'status-ok' if debug_data['ollama']['accessible'] else 'status-error'}">{'‚úÖ' if debug_data['ollama']['accessible'] else '‚ùå'}</span></li>
                                <li>OpenAI: <span class="{'status-ok' if debug_data['configuration']['openai_configured'] else 'status-warning'}">{'‚úÖ' if debug_data['configuration']['openai_configured'] else '‚ö†Ô∏è'}</span></li>
                                <li>Mod√®les: {len(debug_data['ollama']['models'])}</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="col-md-4">
                    <div class="card service-card h-100">
                        <div class="card-header bg-success text-white">
                            <h6><i class="fas fa-image me-2"></i>G√©n√©ration d'Images</h6>
                        </div>
                        <div class="card-body">
                            <ul class="list-unstyled">
                                <li>Stable Diffusion: <span class="{'status-ok' if debug_data['configuration']['use_stable_diffusion'] else 'status-warning'}">{'‚úÖ' if debug_data['configuration']['use_stable_diffusion'] else '‚ö†Ô∏è'}</span></li>
                                <li>Hugging Face: <span class="{'status-ok' if debug_data['configuration']['use_huggingface'] else 'status-warning'}">{'‚úÖ' if debug_data['configuration']['use_huggingface'] else '‚ö†Ô∏è'}</span></li>
                                <li>OpenAI DALL-E: <span class="{'status-ok' if debug_data['configuration']['openai_configured'] else 'status-warning'}">{'‚úÖ' if debug_data['configuration']['openai_configured'] else '‚ö†Ô∏è'}</span></li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="col-md-4">
                    <div class="card service-card h-100">
                        <div class="card-header bg-warning text-dark">
                            <h6><i class="fas fa-video me-2"></i>G√©n√©ration de Vid√©os</h6>
                        </div>
                        <div class="card-body">
                            <ul class="list-unstyled">
                                <li>SVD activ√©: <span class="{'status-ok' if debug_data['configuration']['use_stable_video_diffusion'] else 'status-warning'}">{'‚úÖ' if debug_data['configuration']['use_stable_video_diffusion'] else '‚ö†Ô∏è'}</span></li>
                                <li>SVD accessible: <span class="{'status-ok' if debug_data['stable_video_diffusion']['accessible'] else 'status-error'}">{'‚úÖ' if debug_data['stable_video_diffusion']['accessible'] else '‚ùå'}</span></li>
                                <li>URL: <code>{debug_data['configuration']['svd_url']}</code></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Configuration d√©taill√©e -->
            <div class="row mb-4">
                <div class="col-md-6">
                    <div class="card">
                        <div class="card-header">
                            <h5><i class="fas fa-cog me-2"></i>Configuration IA</h5>
                        </div>
                        <div class="card-body">
                            <h6>Ollama</h6>
                            <ul class="list-unstyled small">
                                <li>Activ√©: {debug_data['configuration']['use_ollama']}</li>
                                <li>URL: <code>{debug_data['configuration']['ollama_url']}</code></li>
                                <li>Mod√®le: <code>{debug_data['configuration']['ollama_model']}</code></li>
                                <li>Accessible: {'‚úÖ' if debug_data['ollama']['accessible'] else '‚ùå'}</li>
                            </ul>
                            
                            <h6>Stable Diffusion</h6>
                            <ul class="list-unstyled small">
                                <li>Activ√©: {debug_data['configuration']['use_stable_diffusion']}</li>
                                <li>URL: <code>{debug_data['configuration']['stable_diffusion_url']}</code></li>
                            </ul>
                            
                            <h6>Stable Video Diffusion</h6>
                            <ul class="list-unstyled small">
                                <li>Activ√©: {debug_data['configuration']['use_stable_video_diffusion']}</li>
                                <li>URL: <code>{debug_data['configuration']['svd_url']}</code></li>
                                <li>Accessible: {'‚úÖ' if debug_data['stable_video_diffusion']['accessible'] else '‚ùå'}</li>
                            </ul>
                        </div>
                    </div>
                </div>
                
                <div class="col-md-6">
                    <div class="card">
                        <div class="card-header">
                            <h5><i class="fas fa-server me-2"></i>Services Application</h5>
                        </div>
                        <div class="card-body">
                            <ul class="list-unstyled">
                                <li>Base de donn√©es: <span class="{'status-ok' if debug_data['services']['database'] else 'status-error'}">{'‚úÖ' if debug_data['services']['database'] else '‚ùå'}</span></li>
                                <li>G√©n√©rateur contenu: <span class="{'status-ok' if debug_data['services']['content_generator'] else 'status-error'}">{'‚úÖ' if debug_data['services']['content_generator'] else '‚ùå'}</span></li>
                                <li>G√©n√©rateur images: <span class="{'status-ok' if debug_data['services']['image_generator'] else 'status-warning'}">{'‚úÖ' if debug_data['services']['image_generator'] else '‚ö†Ô∏è'}</span></li>
                                <li>G√©n√©rateur vid√©os: <span class="{'status-ok' if debug_data['services']['video_generator'] else 'status-warning'}">{'‚úÖ' if debug_data['services']['video_generator'] else '‚ö†Ô∏è'}</span></li>
                                <li>Instagram: <span class="{'status-ok' if debug_data['services']['instagram'] else 'status-warning'}">{'‚úÖ' if debug_data['services']['instagram'] else '‚ö†Ô∏è'}</span></li>
                                <li>Scheduler: <span class="{'status-ok' if debug_data['services']['scheduler'] else 'status-warning'}">{'‚úÖ' if debug_data['services']['scheduler'] else '‚ö†Ô∏è'}</span></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Mod√®les disponibles -->
            <div class="row mb-4">
                <div class="col-md-6">
                    <div class="card">
                        <div class="card-header">
                            <h5><i class="fas fa-brain me-2"></i>Mod√®les Ollama</h5>
                        </div>
                        <div class="card-body">
                            {f'<ul class="list-unstyled">{"".join([f"<li><code>{model}</code></li>" for model in debug_data["ollama"]["models"]])}</ul>' if debug_data['ollama']['models'] else '<p class="text-muted">Aucun mod√®le ou Ollama non accessible</p>'}
                        </div>
                    </div>
                </div>
                
                <div class="col-md-6">
                    <div class="card">
                        <div class="card-header">
                            <h5><i class="fas fa-folder me-2"></i>Structure Dossiers</h5>
                        </div>
                        <div class="card-body">
                            <ul class="list-unstyled">
                                <li>generated/: <span class="{'status-ok' if debug_data['folders']['generated'] else 'status-error'}">{'‚úÖ' if debug_data['folders']['generated'] else '‚ùå'}</span></li>
                                <li>generated/videos/: <span class="{'status-ok' if debug_data['folders']['generated_videos'] else 'status-error'}">{'‚úÖ' if debug_data['folders']['generated_videos'] else '‚ùå'}</span></li>
                                <li>uploads/: <span class="{'status-ok' if debug_data['folders']['uploads'] else 'status-error'}">{'‚úÖ' if debug_data['folders']['uploads'] else '‚ùå'}</span></li>
                                <li>static/: <span class="{'status-ok' if debug_data['folders']['static'] else 'status-error'}">{'‚úÖ' if debug_data['folders']['static'] else '‚ùå'}</span></li>
                                <li>templates/: <span class="{'status-ok' if debug_data['folders']['templates'] else 'status-error'}">{'‚úÖ' if debug_data['folders']['templates'] else '‚ùå'}</span></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Variables d'environnement -->
            <div class="card mb-4">
                <div class="card-header">
                    <h5><i class="fas fa-env me-2"></i>Variables d'environnement</h5>
                </div>
                <div class="card-body">
                    <div class="row">
                        <div class="col-md-6">
                            <h6>Services IA</h6>
                            <ul class="list-unstyled small">
                                <li>USE_OLLAMA: <code>{debug_data['environment']['USE_OLLAMA']}</code></li>
                                <li>OLLAMA_BASE_URL: <code>{debug_data['environment']['OLLAMA_BASE_URL']}</code></li>
                                <li>OLLAMA_MODEL: <code>{debug_data['environment']['OLLAMA_MODEL']}</code></li>
                                <li>USE_STABLE_DIFFUSION: <code>{debug_data['environment']['USE_STABLE_DIFFUSION']}</code></li>
                                <li>USE_STABLE_VIDEO_DIFFUSION: <code>{debug_data['environment']['USE_STABLE_VIDEO_DIFFUSION']}</code></li>
                                <li>USE_HUGGINGFACE: <code>{debug_data['environment']['USE_HUGGINGFACE']}</code></li>
                            </ul>
                        </div>
                        <div class="col-md-6">
                            <h6>APIs et Tokens</h6>
                            <ul class="list-unstyled small">
                                <li>OPENAI_API_KEY: {debug_data['environment']['OPENAI_API_KEY']}</li>
                                <li>INSTAGRAM_ACCESS_TOKEN: {debug_data['environment']['INSTAGRAM_ACCESS_TOKEN']}</li>
                                <li>HUGGINGFACE_API_TOKEN: {debug_data['environment']['HUGGINGFACE_API_TOKEN']}</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Tests de connexion -->
            <div class="card mb-4">
                <div class="card-header">
                    <h5><i class="fas fa-network-wired me-2"></i>Tests de connexion</h5>
                </div>
                <div class="card-body">
                    <div class="row">
                        <div class="col-md-4">
                            <h6>Ollama</h6>
                            <p>
                                <a href="{debug_data['ollama']['test_url']}" target="_blank" class="btn btn-sm btn-outline-primary">
                                    <i class="fas fa-external-link-alt me-1"></i>Tester
                                </a>
                            </p>
                        </div>
                        <div class="col-md-4">
                            <h6>Stable Diffusion</h6>
                            <p>
                                <a href="{debug_data['configuration']['stable_diffusion_url']}" target="_blank" class="btn btn-sm btn-outline-primary">
                                    <i class="fas fa-external-link-alt me-1"></i>Interface Web
                                </a>
                            </p>
                        </div>
                        <div class="col-md-4">
                            <h6>Stable Video Diffusion</h6>
                            <p>
                                {f'<a href="{debug_data["stable_video_diffusion"]["test_url"]}" target="_blank" class="btn btn-sm btn-outline-primary"><i class="fas fa-external-link-alt me-1"></i>Tester</a>' if debug_data['stable_video_diffusion']['test_url'] else '<span class="text-muted">Non configur√©</span>'}
                            </p>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Instructions de d√©pannage -->
            <div class="card mb-4">
                <div class="card-header">
                    <h5><i class="fas fa-tools me-2"></i>Guide de d√©pannage</h5>
                </div>
                <div class="card-body">
                    <div class="accordion" id="troubleshootingAccordion">
                        <div class="accordion-item">
                            <h2 class="accordion-header">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#ollama-help">
                                    Probl√®mes Ollama
                                </button>
                            </h2>
                            <div id="ollama-help" class="accordion-collapse collapse">
                                <div class="accordion-body">
                                    <ol>
                                        <li>Installer: <code>curl -fsSL https://ollama.ai/install.sh | sh</code></li>
                                        <li>D√©marrer: <code>ollama serve</code></li>
                                        <li>T√©l√©charger mod√®le: <code>ollama pull mistral:latest</code></li>
                                        <li>Tester: <code>curl {debug_data['ollama']['test_url']}</code></li>
                                    </ol>
                                </div>
                            </div>
                        </div>
                        
                        <div class="accordion-item">
                            <h2 class="accordion-header">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#svd-help">
                                    Probl√®mes Stable Video Diffusion
                                </button>
                            </h2>
                            <div id="svd-help" class="accordion-collapse collapse">
                                <div class="accordion-body">
                                    <ol>
                                        <li>Installer ComfyUI: <code>git clone https://github.com/comfyanonymous/ComfyUI</code></li>
                                        <li>Installer d√©pendances: <code>cd ComfyUI && pip install -r requirements.txt</code></li>
                                        <li>T√©l√©charger SVD: <code>huggingface-cli download stabilityai/stable-video-diffusion-img2vid-xt</code></li>
                                        <li>D√©marrer avec API: <code>python main.py --port 7862</code></li>
                                        <li>Tester: <code>curl {debug_data['configuration']['svd_url']}/system_stats</code></li>
                                    </ol>
                                </div>
                            </div>
                        </div>
                        
                        <div class="accordion-item">
                            <h2 class="accordion-header">
                                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#gpu-help">
                                    Probl√®mes GPU
                                </button>
                            </h2>
                            <div id="gpu-help" class="accordion-collapse collapse">
                                <div class="accordion-body">
                                    <ul>
                                        <li>V√©rifier CUDA: <code>nvidia-smi</code></li>
                                        <li>V√©rifier PyTorch GPU: <code>python -c "import torch; print(torch.cuda.is_available())"</code></li>
                                        <li>VRAM recommand√©: 8GB+ pour images, 12GB+ pour vid√©os</li>
                                        <li>Si VRAM insuffisant: <code>--lowvram</code> pour ComfyUI</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Raw data -->
            <div class="card">
                <div class="card-header">
                    <h5><i class="fas fa-code me-2"></i>Donn√©es brutes (JSON)</h5>
                </div>
                <div class="card-body">
                    <pre class="small">{json.dumps(debug_data, indent=2, default=str)}</pre>
                </div>
            </div>
            
            <!-- Navigation -->
            <div class="mt-4 text-center">
                <a href="/" class="btn btn-primary me-2">
                    <i class="fas fa-home me-1"></i>Accueil
                </a>
                <a href="/health" class="btn btn-success me-2">
                    <i class="fas fa-heartbeat me-1"></i>Health Check
                </a>
                <a href="/settings" class="btn btn-secondary me-2">
                    <i class="fas fa-cog me-1"></i>Param√®tres
                </a>
                <button onclick="location.reload()" class="btn btn-outline-primary">
                    <i class="fas fa-sync me-1"></i>Actualiser
                </button>
            </div>
        </div>
        
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
    </body>
    </html>
    '''


def setup_system_routes(app, services, routes_ok):
    """Configure les routes syst√®me avec support vid√©o (VERSION COMPL√àTE)"""
    
    @app.route('/health')
    def health_check():
        """Route de sant√© compl√®te avec tous les services"""
        
        # Test Ollama
        ollama_status = False
        ollama_models = []
        if Config.USE_OLLAMA:
            ollama_status, ollama_models = test_ollama_connection()
        
        # Test SVD
        svd_status = False
        svd_queue_info = {}
        if hasattr(app, 'svd_generator') and app.svd_generator:
            svd_status = app.svd_generator.is_available
            if svd_status:
                try:
                    svd_queue_info = app.svd_generator.get_queue_status()
                except:
                    pass
        
        # Statut d√©taill√© des services
        services_status = {
            'database': {
                'available': hasattr(app, 'db_manager') and app.db_manager is not None,
                'type': 'SQLite',
                'path': Config.DATABASE_PATH if hasattr(app, 'db_manager') and app.db_manager else None
            },
            'content_generator': {
                'available': hasattr(app, 'content_generator') and app.content_generator is not None,
                'service': "Ollama" if hasattr(app, 'content_generator') and hasattr(app.content_generator, 'base_url') else "OpenAI" if hasattr(app, 'content_generator') else None,
                'model': Config.OLLAMA_MODEL if Config.USE_OLLAMA else None
            },
            'image_generator': {
                'available': hasattr(app, 'image_generator') and app.image_generator is not None,
                'service': get_active_image_service_name(app),
                'stable_diffusion_available': hasattr(app, 'sd_generator') and app.sd_generator and getattr(app.sd_generator, 'is_available', False),
                'huggingface_available': hasattr(app, 'hf_generator') and app.hf_generator is not None,
                'openai_available': bool(Config.OPENAI_API_KEY)
            },
            'video_generator': {
                'available': svd_status,
                'service': 'Stable Video Diffusion' if svd_status else None,
                'api_url': Config.SVD_API_URL if Config.USE_STABLE_VIDEO_DIFFUSION else None,
                'queue_running': svd_queue_info.get('queue_running', []),
                'queue_pending': svd_queue_info.get('queue_pending', []),
                'max_duration': Config.SVD_MAX_DURATION if Config.USE_STABLE_VIDEO_DIFFUSION else None
            },
            'instagram_publisher': {
                'available': hasattr(app, 'instagram_publisher') and app.instagram_publisher is not None,
                'account_id': Config.INSTAGRAM_ACCOUNT_ID if Config.INSTAGRAM_ACCOUNT_ID else None,
                'token_configured': bool(Config.INSTAGRAM_ACCESS_TOKEN)
            },
            'scheduler': {
                'available': hasattr(app, 'scheduler') and app.scheduler is not None,
                'running': hasattr(app, 'scheduler') and app.scheduler and getattr(app.scheduler, 'is_running', False),
                'check_interval': Config.SCHEDULER_CHECK_INTERVAL
            },
            'routes_loaded': routes_ok
        }
        
        # Configuration IA compl√®te
        ai_config = {
            'content': {
                'use_ollama': Config.USE_OLLAMA,
                'ollama_url': Config.OLLAMA_BASE_URL,
                'ollama_model': Config.OLLAMA_MODEL,
                'ollama_accessible': ollama_status,
                'openai_available': bool(Config.OPENAI_API_KEY),
                'active_service': services_status['content_generator']['service']
            },
            'images': {
                'use_stable_diffusion': Config.USE_STABLE_DIFFUSION,
                'stable_diffusion_url': Config.STABLE_DIFFUSION_URL,
                'use_huggingface': Config.USE_HUGGINGFACE,
                'openai_available': bool(Config.OPENAI_API_KEY),
                'active_service': services_status['image_generator']['service']
            },
            'videos': {
                'use_stable_video_diffusion': Config.USE_STABLE_VIDEO_DIFFUSION,
                'svd_url': Config.SVD_API_URL,
                'svd_accessible': svd_status,
                'max_duration': Config.SVD_MAX_DURATION,
                'default_fps': Config.SVD_DEFAULT_FPS,
                'active_service': services_status['video_generator']['service']
            }
        }
        
        # Statistiques si disponibles
        stats = {}
        if hasattr(app, 'db_manager') and app.db_manager:
            try:
                stats = app.db_manager.get_posts_stats()
            except:
                stats = {}
        
        # Score de sant√© global
        total_services = len(services_status)
        available_services = sum(1 for service in services_status.values() if service.get('available', False))
        health_score = (available_services / total_services) * 100
        
        # Statut global
        if health_score >= 80:
            global_status = "excellent"
        elif health_score >= 60:
            global_status = "good"
        elif health_score >= 40:
            global_status = "fair"
        else:
            global_status = "poor"
        
        return jsonify({
            'status': 'ok',
            'global_status': global_status,
            'health_score': round(health_score, 1),
            'message': 'Instagram Automation avec IA compl√®te (Images + Vid√©os)',
            'services': services_status,
            'ai_configuration': ai_config,
            'ollama_models': ollama_models,
            'statistics': stats,
            'version': '2.0.0-video',
            'timestamp': datetime.now().isoformat(),
            'uptime': 'N/A'  # Pourrait √™tre calcul√© si besoin
        })
    
    @app.route('/debug')
    def debug_info():
        """Route de debug avec informations compl√®tes"""
        
        ollama_status, ollama_models = test_ollama_connection() if Config.USE_OLLAMA else (False, [])
        
        # Test SVD
        svd_status = False
        svd_info = {}
        if hasattr(app, 'svd_generator') and app.svd_generator:
            svd_status = app.svd_generator.is_available
            if svd_status:
                try:
                    svd_info = app.svd_generator.get_status()
                except:
                    pass
        
        debug_data = {
            'system': {
                'python_version': sys.version,
                'current_dir': current_dir,
                'files': [f for f in os.listdir(current_dir) if not f.startswith('.')],
                'python_path': sys.path[:3],
                'platform': platform.system(),
                'architecture': platform.machine()
            },
            'configuration': {
                'use_ollama': Config.USE_OLLAMA,
                'ollama_url': Config.OLLAMA_BASE_URL,
                'ollama_model': Config.OLLAMA_MODEL,
                'use_stable_diffusion': Config.USE_STABLE_DIFFUSION,
                'stable_diffusion_url': Config.STABLE_DIFFUSION_URL,
                'use_stable_video_diffusion': Config.USE_STABLE_VIDEO_DIFFUSION,
                'svd_url': Config.SVD_API_URL,
                'use_huggingface': Config.USE_HUGGINGFACE,
                'openai_configured': bool(Config.OPENAI_API_KEY),
                'instagram_configured': bool(Config.INSTAGRAM_ACCESS_TOKEN and Config.INSTAGRAM_ACCOUNT_ID)
            },
            'ollama': {
                'accessible': ollama_status,
                'models': ollama_models,
                'test_url': f"{Config.OLLAMA_BASE_URL}/api/tags"
            },
            'stable_video_diffusion': {
                'accessible': svd_status,
                'info': svd_info,
                'test_url': f"{Config.SVD_API_URL}/system_stats" if Config.USE_STABLE_VIDEO_DIFFUSION else None
            },
            'services': {
                'database': hasattr(app, 'db_manager') and app.db_manager is not None,
                'content_generator': hasattr(app, 'content_generator') and app.content_generator is not None,
                'image_generator': hasattr(app, 'image_generator') and app.image_generator is not None,
                'video_generator': hasattr(app, 'svd_generator') and app.svd_generator is not None and getattr(app.svd_generator, 'is_available', False),
                'instagram': hasattr(app, 'instagram_publisher') and app.instagram_publisher is not None,
                'scheduler': hasattr(app, 'scheduler') and app.scheduler is not None
            },
            'environment': {
                'USE_OLLAMA': os.getenv('USE_OLLAMA', 'True'),
                'OLLAMA_BASE_URL': os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434'),
                'OLLAMA_MODEL': os.getenv('OLLAMA_MODEL', 'mistral:latest'),
                'USE_STABLE_DIFFUSION': os.getenv('USE_STABLE_DIFFUSION', 'True'),
                'STABLE_DIFFUSION_URL': os.getenv('STABLE_DIFFUSION_URL', 'http://localhost:7861'),
                'USE_STABLE_VIDEO_DIFFUSION': os.getenv('USE_STABLE_VIDEO_DIFFUSION', 'False'),
                'SVD_API_URL': os.getenv('SVD_API_URL', 'http://localhost:7862'),
                'USE_HUGGINGFACE': os.getenv('USE_HUGGINGFACE', 'False'),
                'OPENAI_API_KEY': '‚úÖ Configur√©' if os.getenv('OPENAI_API_KEY') else '‚ùå Non configur√©',
                'INSTAGRAM_ACCESS_TOKEN': '‚úÖ Configur√©' if os.getenv('INSTAGRAM_ACCESS_TOKEN') else '‚ùå Non configur√©',
                'HUGGINGFACE_API_TOKEN': '‚úÖ Configur√©' if os.getenv('HUGGINGFACE_API_TOKEN') else '‚ùå Non configur√©'
            },
            'folders': {
                'generated': os.path.exists('generated'),
                'generated_videos': os.path.exists('generated/videos'),
                'uploads': os.path.exists('uploads'),
                'static': os.path.exists('static'),
                'templates': os.path.exists('templates')
            }
        }
        
        # Template de debug am√©lior√©
        debug_template = generate_debug_template(debug_data)
        return debug_template


def setup_error_handlers(app):
    """Configure les gestionnaires d'erreurs"""
    
    @app.errorhandler(404)
    def not_found_error(error):
        return jsonify({'error': 'Page non trouv√©e'}), 404
    
    @app.errorhandler(500)
    def internal_error(error):
        app.logger.error(f'Erreur serveur: {error}')
        return jsonify({'error': 'Erreur interne du serveur'}), 500
    
    @app.errorhandler(Exception)
    def handle_exception(e):
        app.logger.error(f'Exception non g√©r√©e: {e}')
        return jsonify({'error': 'Erreur inattendue'}), 500


def test_ollama_connection():
    """Test la connexion √† Ollama et retourne les mod√®les (VERSION AM√âLIOR√âE)"""
    try:
        import requests
        response = requests.get(f"{Config.OLLAMA_BASE_URL}/api/tags", timeout=10)
        if response.status_code == 200:
            data = response.json()
            models = [model['name'] for model in data.get('models', [])]
            
            # Test rapide de g√©n√©ration si le mod√®le configur√© existe
            if Config.OLLAMA_MODEL in models:
                try:
                    test_response = requests.post(
                        f"{Config.OLLAMA_BASE_URL}/api/generate",
                        json={
                            "model": Config.OLLAMA_MODEL,
                            "prompt": "Hello",
                            "stream": False
                        },
                        timeout=15
                    )
                    if test_response.status_code == 200:
                        print(f"‚úÖ Test g√©n√©ration Ollama r√©ussi avec {Config.OLLAMA_MODEL}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Test g√©n√©ration Ollama √©chou√©: {e}")
            
            return True, models
        return False, []
    except Exception as e:
        print(f"‚ùå Test connexion Ollama √©chou√©: {e}")
        return False, []


def create_required_directories():
    """Cr√©e tous les dossiers n√©cessaires (VERSION COMPL√àTE)"""
    directories = [
        'templates', 'static', 'uploads', 'generated', 'generated/videos', 'logs',
        'services', 'routes', 'utils', 'static/temp', 'static/generated'
    ]
    
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)
            print(f"‚úÖ Dossier {directory} cr√©√©")
    
    # Cr√©er les fichiers __init__.py
    init_files = ['services/__init__.py', 'routes/__init__.py', 'utils/__init__.py']
    for init_file in init_files:
        if not os.path.exists(init_file):
            with open(init_file, 'w') as f:
                f.write(f'# {init_file}\n')
            print(f"‚úÖ Fichier {init_file} cr√©√©")
    
    # Cr√©er un .gitkeep pour les dossiers vides
    gitkeep_dirs = ['generated/videos', 'uploads', 'static/temp']
    for dir_path in gitkeep_dirs:
        gitkeep_file = os.path.join(dir_path, '.gitkeep')
        if not os.path.exists(gitkeep_file):
            with open(gitkeep_file, 'w') as f:
                f.write('# Garde ce dossier dans Git\n')


def create_env_file():
    """Cr√©e un fichier .env complet avec toutes les variables (VERSION MISE √Ä JOUR)"""
    if not os.path.exists('.env') and not os.path.exists('.env.example'):
        env_content = '''# Configuration Instagram Automation 2.0 avec IA compl√®te

# === SERVICES IA - CONTENU ===
USE_OLLAMA=True
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:latest
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=500
OLLAMA_TIMEOUT=30

# === SERVICES IA - IMAGES ===
USE_STABLE_DIFFUSION=True
STABLE_DIFFUSION_URL=http://localhost:7861
SD_DEFAULT_STEPS=20
SD_DEFAULT_CFG_SCALE=7.0
SD_DEFAULT_SIZE=1024x1024

USE_HUGGINGFACE=False
HUGGINGFACE_API_TOKEN=your_hf_token_here

# === SERVICES IA - VID√âOS (NOUVEAU) ===
USE_STABLE_VIDEO_DIFFUSION=True
SVD_API_URL=http://localhost:7862
SVD_MAX_DURATION=10
SVD_DEFAULT_FPS=8
SVD_DEFAULT_MOTION=0.7

# === OPENAI (OPTIONNEL) ===
# OPENAI_API_KEY=your_openai_api_key_here

# === INSTAGRAM CONFIGURATION ===
INSTAGRAM_ACCESS_TOKEN=your_instagram_access_token
INSTAGRAM_ACCOUNT_ID=your_instagram_business_account_id

# === FLASK CONFIGURATION ===
SECRET_KEY=your_super_secret_key_change_this_in_production
FLASK_ENV=development
FLASK_DEBUG=True

# === DATABASE & STORAGE ===
DATABASE_PATH=posts.db
UPLOAD_FOLDER=uploads
GENERATED_FOLDER=generated
VIDEO_FOLDER=generated/videos

# === SCHEDULER ===
SCHEDULER_CHECK_INTERVAL=60

# === NOTES D'INSTALLATION ===
# 1. Ollama:
#    curl -fsSL https://ollama.ai/install.sh | sh
#    ollama serve
#    ollama pull mistral:latest
#
# 2. Stable Diffusion:
#    git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
#    ./webui.sh --api
#
# 3. Stable Video Diffusion:
#    git clone https://github.com/comfyanonymous/ComfyUI
#    cd ComfyUI && python main.py --port 7862
#
# 4. GPU requis pour g√©n√©ration d'images/vid√©os (8GB+ VRAM recommand√©)
'''
        
        with open('.env.example', 'w') as f:
            f.write(env_content)
        print("‚úÖ Fichier .env.example cr√©√© avec configuration compl√®te")


def test_ollama_cli():
    """Test Ollama depuis la ligne de commande"""
    print("üß™ Test de connexion Ollama...")
    
    try:
        import requests
        
        # Test de base
        print(f"üì° Test connexion sur {Config.OLLAMA_BASE_URL}")
        response = requests.get(f"{Config.OLLAMA_BASE_URL}/api/tags", timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            models = [model['name'] for model in data.get('models', [])]
            
            print("‚úÖ Ollama accessible")
            print(f"üìã Mod√®les disponibles: {models}")
            
            if Config.OLLAMA_MODEL in models:
                print(f"‚úÖ Mod√®le {Config.OLLAMA_MODEL} trouv√©")
                
                # Test de g√©n√©ration
                print("üß† Test de g√©n√©ration de contenu...")
                test_response = requests.post(
                    f"{Config.OLLAMA_BASE_URL}/api/generate",
                    json={
                        "model": Config.OLLAMA_MODEL,
                        "prompt": "√âcris une courte description Instagram pour un caf√© le matin en une phrase.",
                        "stream": False
                    },
                    timeout=30
                )
                
                if test_response.status_code == 200:
                    result = test_response.json()
                    generated_text = result.get('response', 'Pas de r√©ponse')
                    print(f"‚úÖ G√©n√©ration r√©ussie: {generated_text[:100]}...")
                    return True
                else:
                    print(f"‚ùå Erreur g√©n√©ration: {test_response.status_code}")
                    return False
            else:
                print(f"‚ùå Mod√®le {Config.OLLAMA_MODEL} non trouv√©")
                if models:
                    print(f"üí° T√©l√©chargez-le avec: ollama pull {Config.OLLAMA_MODEL}")
                return False
        else:
            print(f"‚ùå Ollama non accessible: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Impossible de se connecter √† Ollama")
        print("üí° V√©rifiez qu'Ollama est d√©marr√© avec: ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå Erreur lors du test: {e}")
        return False


def setup_ollama_service():
    """Guide d'installation automatique d'Ollama"""
    print("üîß Configuration d'Ollama...")
    
    # V√©rifier si Ollama est d√©j√† install√©
    try:
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            print("‚úÖ Ollama d√©j√† install√©")
            print(f"   Version: {result.stdout.strip()}")
            
            # V√©rifier si le service tourne
            if test_ollama_connection()[0]:
                print("‚úÖ Service Ollama en cours d'ex√©cution")
                return True
            else:
                print("‚ö†Ô∏è  Service Ollama non d√©marr√©")
                print("üí° D√©marrez-le avec: ollama serve")
                return False
        else:
            print("‚ùå Ollama install√© mais non fonctionnel")
            return False
            
    except FileNotFoundError:
        print("‚ùå Ollama non install√©")
        
        # Instructions d'installation selon l'OS
        system = platform.system().lower()
        if system == "windows":
            print("üí° Installation Windows:")
            print("   1. T√©l√©chargez depuis: https://ollama.ai/download/windows")
            print("   2. Ou utilisez: winget install ollama")
        elif system == "darwin":  # macOS
            print("üí° Installation macOS:")
            print("   1. curl -fsSL https://ollama.ai/install.sh | sh")
            print("   2. Ou utilisez: brew install ollama")
        else:  # Linux
            print("üí° Installation Linux:")
            print("   1. curl -fsSL https://ollama.ai/install.sh | sh")
        
        return False
    except Exception as e:
        print(f"‚ùå Erreur v√©rification Ollama: {e}")
        return False


def create_systemd_service():
    """Cr√©e un service systemd pour Ollama (Linux seulement)"""
    if platform.system().lower() != "linux":
        print("‚ÑπÔ∏è  Service systemd disponible uniquement sur Linux")
        return
    
    service_content = """[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3

[Install]
WantedBy=default.target
"""
    
    print("üîß Pour cr√©er un service systemd:")
    print("sudo tee /etc/systemd/system/ollama.service > /dev/null << EOF")
    print(service_content)
    print("EOF")
    print("\nsudo systemctl daemon-reload")
    print("sudo systemctl enable ollama")
    print("sudo systemctl start ollama")


def download_recommended_models():
    """T√©l√©charge les mod√®les recommand√©s"""
    recommended_models = [
        "mistral:latest",      # Mod√®le principal
        "llama2:7b",          # Alternative rapide
        "codellama:7b",       # Pour le code si n√©cessaire
    ]
    
    print("üì• Mod√®les recommand√©s pour Instagram Automation:")
    for model in recommended_models:
        print(f"   - {model}")
    
    print("\nüí° Pour t√©l√©charger:")
    for model in recommended_models:
        print(f"ollama pull {model}")


def main():
    """Point d'entr√©e principal"""
    
    print("=" * 60)
    print("ü§ñ INSTAGRAM AUTOMATION AVEC OLLAMA")
    print("=" * 60)
    
    # Cr√©er les dossiers et fichiers n√©cessaires
    create_required_directories()
    create_env_file()
    
    # Charger les variables d'environnement si disponible
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("‚úÖ Variables d'environnement charg√©es depuis .env")
    except ImportError:
        print("‚ö†Ô∏è  python-dotenv non install√© - Variables d'environnement depuis le syst√®me")
    
    # Valider la configuration
    print("\nüîß Validation de la configuration...")
    try:
        config_valid = Config.validate_config()
        if not config_valid:
            print("‚ö†Ô∏è  Configuration incompl√®te - L'application fonctionnera en mode limit√©")
    except Exception as e:
        print(f"‚ùå Erreur validation configuration: {e}")
    
    # Cr√©er l'application
    print("\nüöÄ Cr√©ation de l'application...")
    app = create_app(os.getenv('FLASK_ENV', 'default'))
    
    # Configuration de l'arr√™t propre
    def shutdown_scheduler():
        if hasattr(app, 'scheduler') and app.scheduler:
            print("üîÑ Arr√™t du scheduler...")
            app.scheduler.stop()
    
    atexit.register(shutdown_scheduler)
    
    # Informations de d√©marrage
    print("\n" + "=" * 60)
    print("üåü APPLICATION PR√äTE")
    print("=" * 60)
    print(f"üìç URL principale: http://localhost:5000")
    print(f"üîç Health check: http://localhost:5000/health")
    print(f"üêõ Debug info: http://localhost:5000/debug")
    print(f"ü§ñ Configuration IA: {'Ollama' if Config.USE_OLLAMA else 'OpenAI'}")
    
    if Config.USE_OLLAMA:
        print(f"üß† Mod√®le: {Config.OLLAMA_MODEL}")
        print(f"üåê URL Ollama: {Config.OLLAMA_BASE_URL}")
        print("\nüí° Pour utiliser Ollama:")
        print("   1. Installer: curl -fsSL https://ollama.ai/install.sh | sh")
        print("   2. D√©marrer: ollama serve")
        print("   3. T√©l√©charger le mod√®le: ollama pull mistral:latest")
    
    print("\nüöÄ D√©marrage du serveur...")
    
    # Lancer l'application
    try:
        app.run(
            host='0.0.0.0',
            port=int(os.getenv('PORT', 5000)),
            debug=app.config.get('DEBUG', True),
            use_reloader=False  # √âviter les probl√®mes avec le scheduler
        )
    except KeyboardInterrupt:
        print("\nüõë Arr√™t de l'application demand√©")
    except Exception as e:
        print(f"\n‚ùå Erreur lors du d√©marrage: {e}")
    finally:
        print("üëã Application ferm√©e")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Instagram Automation avec Ollama')
    parser.add_argument('--test-ollama', action='store_true', 
                       help='Tester la connexion Ollama')
    parser.add_argument('--setup-ollama', action='store_true',
                       help='Guide de configuration Ollama')
    parser.add_argument('--create-service', action='store_true',
                       help='Cr√©er un service systemd (Linux)')
    parser.add_argument('--download-models', action='store_true',
                       help='Afficher les commandes pour t√©l√©charger les mod√®les')
    parser.add_argument('--config-check', action='store_true',
                       help='V√©rifier la configuration seulement')
    
    args = parser.parse_args()
    
    if args.test_ollama:
        test_ollama_cli()
    elif args.setup_ollama:
        setup_ollama_service()
    elif args.create_service:
        create_systemd_service()
    elif args.download_models:
        download_recommended_models()
    elif args.config_check:
        print("üîß V√©rification de la configuration...")
        try:
            Config.validate_config()
            print("‚úÖ Configuration valide")
        except Exception as e:
            print(f"‚ùå Erreur de configuration: {e}")
    else:
        # Lancement normal de l'application
        main()